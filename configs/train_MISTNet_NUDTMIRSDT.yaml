model:
  network:
    name: MISTNet
  optimizer:
    type: AdamW
    init_lr: !!float 1e-3
    betas: [ 0.9, 0.999 ]
    weight_decay: !!float 1e-4
  lr_scheduler:
    warmup_iters: -1  # number of warmup iters (-1 for no warmup)
    scheduler:
      type: StepLR
      step_interval: epoch  # iter or epoch (every iter or every epoch to update once)
      step_size: 5
      gamma: 0.5
  loss:
    num_preds: 1  # number of predicted masks (default 1, when using deep supervision > 1)
    loss_1:
      type: SoftIoULoss
      weight: 1
      smooth: 1
      reduction: mean
    loss_2:
      type: SufficiencyLoss
      weight: 0.01
      temperature: 1
      reduction: mean

dataset:
  name: NUDT-MIRSDT
  root: ./data/NUDT-MIRSDT
  full_supervision: True

train:
  exp_name: MISTNet_NUDTMIRSDT
  batch_size: 12
  num_workers: 16
  total_epochs: 50
  log_interval: 50
  save_interval: 1
  val_interval: 1
  resume: